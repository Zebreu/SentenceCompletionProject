Les différents algorithmes de type word2vec ont été implémentés en s'inspirant grandement de celle du skip-gram avec softmax hiérarchique dans Gensim [1]. Les fonctions "train_sentence" utilisées lors des tests sont celles en Cython (avec l'optimisation "1") [Voir les fichiers .pyx]. L'optimisation "0" a aussi été implémentée, mais la "2" ne l'a en général pas été. De plus, la fonctionnement correct des fonctions "train_sentence" écrites directement en Python/Numpy n'a pas été testé entièrement étant donnant la lenteur de ces fonctions.

[1] Rehurek, R., \& Sojka, P. (2010). Software framework for topic modelling with large corpora. In {\it Proceedings of LREC 2010 workshop New Challenges for NLP Frameworks}, 46-50.